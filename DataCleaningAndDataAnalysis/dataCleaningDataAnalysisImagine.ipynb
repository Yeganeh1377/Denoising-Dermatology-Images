{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.io import read_image\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data as tdata\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import collections\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pandas as pd\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the table\n",
    "\n",
    "data = pd.read_csv(\"../imagine/image_quality.csv\")\n",
    "\n",
    "train_path = \"../imagine/train.pickle\"\n",
    "test_path = '../imagine/test.pickle'\n",
    "with open(train_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "\n",
    "train_file = x.loc[x.class_label.isin([\"psoriasis\"]), :]\n",
    "train_file.reset_index(inplace=True)\n",
    "train_file = train_file.loc[:, ~train_file.columns.str.contains('^index')]\n",
    "\n",
    "\n",
    "with open(test_path, 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "test_file = x.loc[x.class_label.isin([\"psoriasis\"]), :]\n",
    "test_file.reset_index(inplace=True)\n",
    "test_file = test_file.loc[:, ~test_file.columns.str.contains('^index')]\n",
    "train_images = train_file.image_id.tolist()\n",
    "train_images2 = [i[:-4] for i in train_images]\n",
    "#print(test_images2)\n",
    "train_meta_data = data.loc[data.platformImageId.isin(train_images2)]\n",
    "\n",
    "test_images = test_file.image_id.tolist()\n",
    "test_images2 = [i[:-4] for i in test_images]\n",
    "#print(test_images2)\n",
    "test_meta_data = data.loc[data.platformImageId.isin(test_images2)]\n",
    "len(train_meta_data), len(test_meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-short",
   "metadata": {},
   "source": [
    "# Checking that All the rows exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be967d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"imagine/images\"\n",
    "#create a list of the unique image ids that will iterately check their existance in the file\n",
    "imgId_list = data['platformImageId'].unique().tolist()\n",
    "print(len(imgId_list))\n",
    "#a list of images that dont exist\n",
    "nonExisting = []\n",
    "\n",
    "for Id in imgId_list:\n",
    "    path = data_dir+\"/\"+Id+\".png\"\n",
    "    if Path(path).is_file():\n",
    "        pass\n",
    "    else:\n",
    "        nonExisting.append(Id)\n",
    "print(len(nonExisting))\n",
    "print(len(data.loc[(data[\"platformImageId\"].isin(nonExisting))]))\n",
    "data = data.loc[(~data[\"platformImageId\"].isin(nonExisting))] \n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"imagine/images\"\n",
    "blurry = data_dir+\"/\"+data.loc[data.blurry == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(blurry.iloc[0])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "far = data_dir+\"/\"+data.loc[data.too_far_away == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(far.iloc[1])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "light = data_dir+\"/\"+data.loc[data.bad_light == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(light.iloc[3])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "covered = data_dir+\"/\"+data.loc[data.lesion_covered == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(covered.iloc[2])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "resolution = data_dir+\"/\"+data.loc[data.low_resolution == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(resolution.iloc[0])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "framing = data_dir+\"/\"+data.loc[data.bad_framing == True, \"platformImageId\"]+\".png\"\n",
    "image = Image.open(framing.iloc[2])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "SNV = data_dir+\"/\"+data.loc[data.diagnosis == \"SNV\", \"platformImageId\"]+\".png\"\n",
    "image = Image.open(SNV.iloc[2])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "lesion = data_dir+\"/\"+data.loc[data.diagnosis == \"L98.2\", \"platformImageId\"]+\".png\"\n",
    "image = Image.open(lesion.iloc[0])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "plt.show()\n",
    "CNS = data_dir+\"/\"+data.loc[data.diagnosis == \"CNS\", \"platformImageId\"]+\".png\"\n",
    "image = Image.open(CNS.iloc[2])\n",
    "image = T.ToTensor()(image)\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data)\n",
    "#find any row that has Nan values\n",
    "data2 = data[data['diagnosis'].isna()]\n",
    "print(len(data[data['diagnosis'].isna()]), len(data[data['platformImageId'].isna()]), len(data[data['dermId'].isna()]), len(data[data['patientId'].isna()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399eb95f",
   "metadata": {},
   "source": [
    "## delete CNV data as they are for this task trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8273c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNV= skin not visible, CNS: clear skin, NEP = quality issues\n",
    "#delete the CNV data\n",
    "data = data[data['diagnosis'] != 'SNV']\n",
    "print(len(data.dermId.unique())) #12 dermatologists in total\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98b6f3",
   "metadata": {},
   "source": [
    "# Ensuring no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f326480",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/imaginePilot-v1.0/imagine/updated_image_quality.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "#data.head()\n",
    "print(len(data))\n",
    "#delete the duplicate images\n",
    "data.drop_duplicates('platformImageId', inplace=True)\n",
    "data.reset_index(inplace=True) \n",
    "print(len(data))\n",
    "data = data.loc[:, ~data.columns.str.contains('^index')]\n",
    "data\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc4d21",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea377464",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEP_count = np.size(np.where(data[\"diagnosis\"]== \"NEP\"))\n",
    "data_count = data.shape\n",
    "print(NEP_count)\n",
    "print(data_count)\n",
    "bad_framing_count = np.size(np.where(~data['bad_framing'].isnull()))\n",
    "bad_light_count = np.size(np.where(~data['bad_light'].isnull()))\n",
    "blurry_count = np.size(np.where(~data['blurry'].isnull()))\n",
    "lesion_covered_count = np.size(np.where(~data['lesion_covered'].isnull()))\n",
    "low_resolution_count = np.size(np.where(~data['low_resolution'].isnull()))\n",
    "too_far_away_count = np.size(np.where(~data['too_far_away'].isnull()))\n",
    "\n",
    "print(\"bad framing:\", bad_framing_count, \"bad_light:\", bad_light_count, \"blurry:\", blurry_count, \"lesion covered:\", lesion_covered_count, \"low resolution:\", low_resolution_count, \"too far away:\", too_far_away_count)\n",
    "x = np.array([\"bad framing\",\"bad light\",\"blurry\",\"lesion covered\",\"low resolution\",\"too far away\"])\n",
    "y = np.array([bad_framing_count, bad_light_count, blurry_count, lesion_covered_count, low_resolution_count, too_far_away_count])\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.bar(x,y)\n",
    "for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center',\n",
    "                 Bbox = dict(facecolor = 'yellow', alpha =.8))\n",
    "plt.title(\"Distribution of Quality errors\")\n",
    "plt.xlabel(\"Error type\")\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.savefig(\"errorTypeNumbers.png\")     \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d2fe3",
   "metadata": {},
   "source": [
    "# Patient count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cea4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many patients in total\n",
    "patient_count = len(train_file.patientId.unique())+len(test_file.patientId.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check how many patients are diagnosed different types of lesions\n",
    "print(\"number of patients that are only diagnosed NEP: \", len(patient.loc[~patient[\"NEP\"].isna() & patient[\"CNS\"].isna() & patient[\"lesion\"].isna()]))\n",
    "print(\"number of patients that are only diagnosed CNS or lesion: \", len(patient.loc[patient[\"NEP\"].isna()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa49680c",
   "metadata": {},
   "source": [
    "# Split the data into common, NEP and CNS|lesion on patient level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNS |& lesion: train section 1\n",
    "# Note: a patient can have images of both cns and lesion, but each image is either lesion OR CNS\n",
    "lesion_cns_patients = patient.loc[patient[\"NEP\"].isna(),[\"patientId\", \"NEP\",\"CNS\",\"lesion\"]] \n",
    "lesion_cns_index = data.patientId.isin(lesion_cns_patients.patientId.tolist()).values.tolist()\n",
    "lesion_cns_images = data.iloc[lesion_cns_index]\n",
    "print(\"lesion or CNS patients details: \", \"#patients: \",len(lesion_cns_patients),\"#images with CNS: \",lesion_cns_patients.CNS.sum(), \"#images with lesion: \",lesion_cns_patients.lesion.sum(), \"#images: \",len(lesion_cns_images))\n",
    "\n",
    "#NEP only: test 1\n",
    "NEP_patients = patient.loc[~patient[\"NEP\"].isna() & patient[\"CNS\"].isna() & patient[\"lesion\"].isna(),[\"patientId\", \"NEP\", \"CNS\",\"lesion\"]]\n",
    "NEP_index = data.patientId.isin(NEP_patients.patientId.tolist()).values.tolist()\n",
    "NEP_images = data.iloc[NEP_index]\n",
    "print(\"Only NEP patients details: \", \"#patiens: \",len(NEP_patients),\"#NEP images: \", NEP_patients.NEP.sum(), \"NEP images: \", len(NEP_images))\n",
    "\n",
    "#common\n",
    "lesion_cns_nep_patients = patient.loc[~patient[\"NEP\"].isna() & ~patient[\"CNS\"].isna() & ~patient[\"lesion\"].isna(),[\"patientId\", \"NEP\",\"CNS\",\"lesion\"]]\n",
    "lesion_cns_nep_index = data.patientId.isin(lesion_cns_nep_patients.patientId.tolist()).values.tolist()\n",
    "lesion_cns_nep_images = data.iloc[lesion_cns_nep_index]\n",
    "print(\"patients with a mix of all the labels: \", \"#patients\", len(lesion_cns_nep_patients), \"# CNS images: \", lesion_cns_nep_patients.CNS.sum(), \"# NEP images: \", lesion_cns_nep_patients.NEP.sum(),\"# lesion images: \", lesion_cns_nep_patients.lesion.sum(), \"#images\", len(lesion_cns_nep_images))\n",
    "\n",
    "lesion_nep_patients = patient.loc[~patient[\"NEP\"].isna() & patient[\"CNS\"].isna() & ~patient[\"lesion\"].isna(),[\"patientId\", \"NEP\",\"CNS\",\"lesion\"]]\n",
    "lesion_nep_index = data.patientId.isin(lesion_nep_patients.patientId.tolist()).values.tolist()\n",
    "lesion_nep_images = data.iloc[lesion_nep_index]\n",
    "print(\"patients with a mix of lesion nep labels: \", \"#patients: \",len(lesion_nep_patients),\"# lesion images: \", lesion_nep_patients.lesion.sum(), \"#NEP images: \", lesion_nep_patients.NEP.sum(), \"# lesion nep images\", len(lesion_nep_images))\n",
    "\n",
    "cns_nep_patients = patient.loc[~patient[\"NEP\"].isna() & ~patient[\"CNS\"].isna() & patient[\"lesion\"].isna(),[\"patientId\", \"NEP\",\"CNS\",\"lesion\"]]\n",
    "cns_nep_index = data.patientId.isin(cns_nep_patients.patientId.tolist()).values.tolist()\n",
    "cns_nep_images = data.iloc[cns_nep_index]\n",
    "print(\"patients with a mix of cns nep labels: \", \"#patients: \", len(cns_nep_patients),\"#cns images: \", cns_nep_patients.CNS.sum(), \"#nep images: \", cns_nep_patients.NEP.sum(), \"#images: \", len(cns_nep_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_labels = lesion_cns_nep_images.append(lesion_nep_images, ignore_index=True)\n",
    "common_labels = common_labels.append(cns_nep_images, ignore_index=True)\n",
    "print(len(common_labels.platformImageId.unique()),len(lesion_cns_nep_images)+len(lesion_nep_images)+len(cns_nep_images), len(cns_nep_patients)+len(lesion_nep_patients)+len(lesion_cns_nep_patients), len(common_labels.patientId.unique()))\n",
    "common_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = data.patientId.unique()\n",
    "counts = np.sum(patient, 0)\n",
    "#plot classes\n",
    "x = np.array([\"CNS\",\"NEP\",\"other\",\"psoriasis\", \"dermatitis\", \"acne\",\"rosacea\"])\n",
    "y = np.array([counts.CNS, counts.NEP, counts.other, counts.psoriasis, counts.dermatitis, counts.acne, counts.rosacea])\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.bar(x,y)\n",
    "for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center',\n",
    "                 Bbox = dict(facecolor = 'yellow', alpha =.8))\n",
    "plt.title(\"Distribution of Classes over total images\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.savefig(\"classdistribution.png\")     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425a5ca",
   "metadata": {},
   "source": [
    "### check for superusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient[\"count\"] = np.sum(patient, 1)\n",
    "#print(patient)\n",
    "df = patient[patient[\"count\"] > 15]\n",
    "print(len(df))\n",
    "#print(test)\n",
    "superpatientsId = df.patientId #202 patients in total, 170 of these patients are in training. \n",
    "print(len(superpatientsId))\n",
    "indices_superuserimages = np.where(test.patientId.isin(superpatientsId)) #4888 images for these patients on train dataset\n",
    "superuser_images = test.iloc[indices_superuserimages]\n",
    "print(len(superuser_images))\n",
    "\n",
    "superuser_images = superuser_images.sort_values('patientId',ascending = False).groupby('patientId').head(15) #for each value of patientId I chose the first 15 images\n",
    "print(superuser_images)\n",
    "\n",
    "\n",
    "test= test.drop(test[(test.platformImageId.isin(superuser_images.platformImageId.tolist()).values.tolist()) & (test.patientId.isin(superpatientsId))].index)\n",
    "print(\"test\",test)\n",
    "\n",
    "test.reset_index(inplace=True) \n",
    "test = test.loc[:, ~test.columns.str.contains('index')]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
