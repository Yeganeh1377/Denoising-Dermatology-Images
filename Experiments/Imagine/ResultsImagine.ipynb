{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01524cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re \n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import text \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch.nn.functional import mse_loss as mse\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data as tdata\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle # extra\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "from kornia.losses import SSIMLoss, PSNRLoss\n",
    "from kornia.metrics import psnr, ssim\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import torch.utils.tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "torch.manual_seed(1996)\n",
    "torch.cuda.manual_seed(1996)\n",
    "np.random.seed(1996)\n",
    "random.seed(1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1bb7f",
   "metadata": {},
   "source": [
    "# Load the required models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class costumeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    data_path: path of all the images as a list, each element in the list is path of an image\n",
    "    label_map: dataframe of corresponding labels that is loaded: maps label to image-id\n",
    "    class_map: a dictionary of classes: maps labels to encoded labels\n",
    "    patient_map: a dataframe that maps patient_id to frequency of each label among the images of that patient\n",
    "    label_col: the column in label file where the labels are saved: here is diagnosis\n",
    "    transform: the type of transform. As default it is none, meaning that the images will only be transformed to tensors\n",
    "    it can also have augmentations\n",
    "    noisy_transform: the type of noise implemented in the image. default: none, no noisy data\n",
    "    val_split: val_train ratio. default: None, no validation split.\n",
    "    \n",
    "    Return Dataset class representing our data set\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir, \n",
    "                 label_map, \n",
    "                 class_map, \n",
    "                 #patient_map,\n",
    "                 label_col, \n",
    "                 augment = None, \n",
    "                 noisy_transform= None, \n",
    "                 image_size = (224,224)\n",
    "                ):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.label_map = label_map #loaded it in the loader once\n",
    "        self.augment = augment\n",
    "        self.noisy_transform = noisy_transform\n",
    "        self.class_map = class_map\n",
    "        self.label_col = label_col\n",
    "        self.image_size = image_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __len__(self): \n",
    "        '''returns size of the dataset'''\n",
    "        return len(self.label_map)\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        'Generates one sample of data'  \n",
    "        img_path = self.data_dir+\"/\"+self.label_map.loc[index, self.label_col]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        label = self.class_map[self.label_map.loc[index, \"class_label\"]]\n",
    "  \n",
    "        if self.transform: \n",
    "            image = self.transform(img)\n",
    "        if self.augment: \n",
    "            augment_image = self.augment(image)\n",
    "            if self.noisy_transform: \n",
    "                noisy_image = self.noisy_transform(augment_image)\n",
    "                return augment_image, noisy_image, label\n",
    "\n",
    "        else: \n",
    "            if self.noisy_transform: \n",
    "                noisy_image = self.noisy_transform(image)\n",
    "                return image, noisy_image, label\n",
    "            \n",
    "                \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2, padding=1) \n",
    "    \n",
    "        # Decoder       \n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(128*2, 64, 4, stride=2, padding=1)\n",
    "       \n",
    "        self.deconv2 = nn.ConvTranspose2d(64*2, 32, 4, stride=2, padding=1)     \n",
    "        self.deconv1 = nn.ConvTranspose2d(32*2, 3, 4, stride=2, padding=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.50)\n",
    "        self.act_fn = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.out_fn = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):       \n",
    "     \n",
    "        z1 = self.conv1(x)       \n",
    "        z1 = self.act_fn(z1)\n",
    "        z1 = self.dropout(z1)  \n",
    "        \n",
    "        z2 = self.conv2(z1)        \n",
    "        z2 = self.act_fn(z2)\n",
    "        z2 = self.dropout(z2)\n",
    "        \n",
    "        z3 = self.conv3(z2)     \n",
    "        z3 = self.act_fn(z3)\n",
    "        z3 = self.dropout(z3)\n",
    "\n",
    "        z4 = self.conv4(z3)        \n",
    "        z = self.act_fn(z4) \n",
    "        # Decoder\n",
    "        x_hat = self.deconv4(z)\n",
    "        x_hat = self.act_fn(x_hat)\n",
    "        x_hat = torch.cat((x_hat,z3),1)  \n",
    "        x_hat = self.deconv3(x_hat)\n",
    "        x_hat = self.act_fn(x_hat)\n",
    "        \n",
    "        x_hat = torch.cat((x_hat,z2),1)     \n",
    "        x_hat = self.deconv2(x_hat)\n",
    "        x_hat = self.act_fn(x_hat)\n",
    "        x_hat = torch.cat((x_hat,z1),1)   \n",
    "        x_hat = self.deconv1(x_hat)\n",
    "        x_hat = self.out_fn(x_hat)\n",
    "        return {'z': z, 'x_hat': x_hat}\n",
    "\n",
    "    \n",
    "\"_______________set experiment__________________\"\n",
    "def set_experiment(model, params):\n",
    "    # This function initializes all the modules needed to train the model given a set of parameters.\n",
    "    # Transform\n",
    "    composed = {\n",
    "        'augment': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #transforms.Resize(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomAffine(degrees=(10), scale=(0.8,1.2)),\n",
    "            transforms.ToTensor()\n",
    "            ]),\n",
    "        \n",
    "        'noisy': transforms.Compose([\n",
    "            transforms.ToPILImage(),            \n",
    "            transforms.RandomApply([transforms.ColorJitter(brightness=[params[\"brightness\"], params[\"brightness\"]])],p=params[\"p\"]),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "    }\n",
    "    data_dir = \"../imagine/images\"\n",
    "    clinic_dir = \"../imagine/clinic\"\n",
    "    train_path = \"../imagine/train.pickle\"\n",
    "    test_path = '../imagine/test.pickle'\n",
    "    valid_path = '../imagine/valid.pickle'\n",
    "    data_report_dir = \"../imagine_report/report\"\n",
    "    added_path = \"../imagine_report/added.csv\"\n",
    "    light_path = \"../imagine_report/light.csv\"\n",
    "    dark_path = \"../imagine_report/dark.csv\"\n",
    "    natural_path = \"../imagine_report/natural.csv\"\n",
    "    added_appendix_path = \"../imagine_report/added_appendix.csv\"\n",
    "    added_report_path = \"../imagine_report/added_report.csv\"\n",
    "    clinic_path = \"../imagine/clinic.csv\"\n",
    "    \n",
    "    class_map = {\"psoriasis\":0}\n",
    "    label_col = \"image_id\"\n",
    "\n",
    "    with open(train_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "\n",
    "    train_file = x.loc[x.class_label.isin([\"psoriasis\"]), :]\n",
    "    train_file.reset_index(inplace=True)\n",
    "    train_file = train_file.loc[:, ~train_file.columns.str.contains('^index')]\n",
    "  \n",
    "\n",
    "    with open(test_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "  \n",
    "    test_file = x.loc[x.class_label.isin([\"psoriasis\"]), :]\n",
    "    test_file.reset_index(inplace=True)\n",
    "    test_file = test_file.loc[:, ~test_file.columns.str.contains('^index')]\n",
    "    \n",
    "\n",
    "    with open(valid_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "   \n",
    "    valid_file = x.loc[x.class_label.isin([\"psoriasis\"]), :]\n",
    "    valid_file.reset_index(inplace=True)\n",
    "    valid_file = valid_file.loc[:, ~valid_file.columns.str.contains('^index')]\n",
    "    \n",
    "    added_file, light_file, dark_file, natural_file,added_appendix_file, added_report_file, clinic_file = pd.read_csv(added_path, sep=\";\"), pd.read_csv(light_path, sep=\";\"), pd.read_csv(dark_path, sep=\";\"), pd.read_csv(natural_path, sep=\";\"), pd.read_csv(added_appendix_path, sep=\";\"), pd.read_csv(added_report_path, sep=\";\"),pd.read_csv(clinic_path, sep=\";\")\n",
    "    added_file = added_file.loc[:, ~added_file.columns.str.contains('Unnamed')]\n",
    "    light_file = light_file.loc[:, ~light_file.columns.str.contains('Unnamed')]\n",
    "    dark_file = dark_file.loc[:, ~dark_file.columns.str.contains('Unnamed')]\n",
    "    natural_file = natural_file.loc[:, ~natural_file.columns.str.contains('Unnamed')]\n",
    "    added_appendix_file = added_appendix_file.loc[:, ~added_appendix_file.columns.str.contains('Unnamed')]\n",
    "    added_report_file = added_report_file.loc[:, ~added_report_file.columns.str.contains('Unnamed')]\n",
    "    clinic_file = clinic_file.loc[:, ~clinic_file.columns.str.contains('Unnamed')]\n",
    "    # load the dataset\n",
    "    train_dataset = costumeDataset(data_dir = data_dir, \n",
    "             label_map = train_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = composed[\"augment\"], \n",
    "             noisy_transform= composed[\"noisy\"],\n",
    "             image_size = params['image_size'])\n",
    "    \n",
    "    test_dataset = costumeDataset(data_dir = data_dir, \n",
    "             label_map = test_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "\n",
    "    valid_dataset = costumeDataset(data_dir = data_dir, \n",
    "             label_map = valid_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size']) \n",
    "    # for visualising in the report\n",
    "    added_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = added_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    light_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = light_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    dark_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = dark_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    natural_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = natural_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    \n",
    "    added_appendix_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = added_appendix_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    added_report_dataset = costumeDataset(data_dir = data_report_dir, \n",
    "             label_map = added_report_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size'])\n",
    "    clinic_dataset = costumeDataset(data_dir = clinic_dir, \n",
    "             label_map = clinic_file, \n",
    "             class_map = class_map, \n",
    "             label_col = label_col, \n",
    "             augment = None, \n",
    "             noisy_transform= composed[\"noisy\"], \n",
    "             image_size = params['image_size']\n",
    "    \n",
    "\n",
    "    #set data iterators\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    test_loader =  DataLoader(\n",
    "        test_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    \n",
    "\n",
    "    # for visualising\n",
    "    added_loader = DataLoader(\n",
    "        added_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    light_loader =  DataLoader(\n",
    "        light_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "\n",
    "    dark_loader =  DataLoader(\n",
    "        dark_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    natural_loader =  DataLoader(\n",
    "        natural_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    added_appendix_loader =  DataLoader(\n",
    "        added_appendix_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    added_report_loader =  DataLoader(\n",
    "        added_report_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    clinic_loader =  DataLoader(\n",
    "        clinic_dataset, batch_size=params['batch_size'], shuffle=False, \n",
    "        num_workers=4, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Get experiment modules\n",
    "    experiment_modules ={\n",
    "    'augment': composed[\"augment\"],\n",
    "    'noisy': composed[\"noisy\"],\n",
    "    'train_loader': train_loader, \n",
    "    'valid_loader': valid_loader,\n",
    "    'test_loader': test_loader,\n",
    "    'added_loader': added_loader,\n",
    "    'light_loader': light_loader,\n",
    "    'dark_loader': dark_loader,\n",
    "    'natural_loader':natural_loader,\n",
    "    'added_appendix_loader': added_appendix_loader,\n",
    "    'added_report_loader': added_report_loader,\n",
    "    'clinic_loader': clinic_loader}\n",
    "    return experiment_modules\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Autoencoder()\n",
    "net.to(\"cuda\")\n",
    "summary(net, (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc31f2",
   "metadata": {},
   "source": [
    "# Loading The Benchmark and Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_GAMMA0.05_P0.6_BRIGHTNESS0.8.pickle', 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "data_items = x. items()\n",
    "data_list = list(data_items)\n",
    "df1 = pd.DataFrame(data_list)\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad885532",
   "metadata": {},
   "source": [
    "# Get Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "def get_learningCurve(df, b):\n",
    "    epoch = df.iloc[0,1]\n",
    "    train_loss = df.iloc[5,1] #ssim train\n",
    "    test_loss = df.iloc[14,1] # ssim valid\n",
    "    psnr_train = df.iloc[7,1]\n",
    "    psnr_test = df.iloc[15,1]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2,figsize=(15,10))\n",
    "    axs[0].plot(epoch,train_loss, label='Train')\n",
    "    axs[0].plot(epoch,test_loss, label='Test')\n",
    "    axs[0].set_title('SSIM Loss', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].set_xlabel('Epoch', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].set_ylabel('SSIM Loss', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].legend(loc='best')\n",
    "\n",
    "    axs[1].plot(epoch,psnr_train, label='Train')\n",
    "    axs[1].plot(epoch,psnr_test, label='Test')\n",
    "    axs[1].set_title('PSNR Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].set_xlabel('Epoch', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].set_ylabel('PSNR Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].legend(loc='best')\n",
    "    fig.suptitle(f'Learning Curve on Imagine Dataset With Noise Level {b}', fontsize=20, fontweight=\"bold\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"IMAGINE_RESULTS/LearningCurve_BENCHMARK_IMAGINE_LARGEEPOCH_{b}.png\")     \n",
    "    plt.show()\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves for exp 1 of classifier\n",
    "def get_learningCurve_class(df, gamma):\n",
    "    epoch = df.iloc[0,1]\n",
    "    train_loss = df.iloc[1,1] #total loss train\n",
    "    valid_loss = df.iloc[8,1] #total loss valid\n",
    "    psnr_train = df.iloc[7,1]\n",
    "    psnr_valid = df.iloc[15,1]\n",
    "    acc_train = df.iloc[6,1]\n",
    "    acc_valid = df.iloc[9,1]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3,figsize=(15,10))\n",
    "    axs[0].plot(epoch,train_loss, label='Train')\n",
    "    axs[0].plot(epoch,valid_loss, label='Validation')\n",
    "    axs[0].set_title('Total Loss', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].set_xlabel('Epoch', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].set_ylabel('Total Loss', fontsize=16, fontweight=\"bold\")\n",
    "    axs[0].legend(loc='best')\n",
    "\n",
    "    axs[1].plot(epoch,psnr_train, label='Train')\n",
    "    axs[1].plot(epoch,psnr_valid, label='Validation')\n",
    "    axs[1].set_title('PSNR Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].set_xlabel('Epoch', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].set_ylabel('PSNR Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[1].legend(loc='best')\n",
    "    \n",
    "    axs[2].plot(epoch,acc_train, label='Train')\n",
    "    axs[2].plot(epoch,acc_valid, label='Validation')\n",
    "    axs[2].set_title('Accuracy Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[2].set_xlabel('Epoch', fontsize=16, fontweight=\"bold\")\n",
    "    axs[2].set_ylabel('Accuracy Score', fontsize=16, fontweight=\"bold\")\n",
    "    axs[2].legend(loc='best')\n",
    "    \n",
    "    \n",
    "    fig.suptitle(f'Learning Curve on Imagine Dataset With Noise Level 0.4 and Classifier Weight of {gamma}', fontsize=20, fontweight=\"bold\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"LearningCurve_CLASSIFIER_ISIC_0.4_WEIGHT{gamma}.png\")     \n",
    "    plt.show()\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb39b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_learningCurve(df5, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eef93",
   "metadata": {},
   "source": [
    "# Get psnr and ssim of the last epoch in benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssim_psnr_noisy_model(model_file,b, params):\n",
    "    model = torch.load(model_file)\n",
    "    model.cuda()\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "\n",
    "    \n",
    "    #setup metrics\n",
    "    rssimnx = 0.0\n",
    "    rpsnrnx = 0.0\n",
    "    rssimxh = 0.0\n",
    "    rpsnrxh = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for x, noisy_x, y in experiment_modules[\"valid_loader\"]:\n",
    "            x, noisy_x, y= x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "            \n",
    "            outputs = model(noisy_x) \n",
    "            x_hat = outputs['x_hat']\n",
    "\n",
    "            ssimnoisyxtmp = ssim(x,noisy_x, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimnoisyx = ssimnoisyxtmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            msenoisyxtmp = mse(x,noisy_x, reduction = \"none\") # BxCxHxW\n",
    "            msexhatxtmp = mse(x,x_hat, reduction = \"none\")# BxCxHxW\n",
    "            print(\"msenoisyxtmp\", msenoisyxtmp.size())\n",
    "            print(\"msexhatxtmp\", msexhatxtmp.size())\n",
    "            msenoisyx = msenoisyxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            msexhatx = msexhatxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            print(\"msenoisyx\",msenoisyx.size())\n",
    "            print(\"msexhatx\",msexhatx.size())\n",
    "            print(\"msenoisyx\",msenoisyx.size())\n",
    "            print(\"msexhatx\",msexhatx.size())\n",
    "            psnrnoisyx = 10.0 * torch.log10(1.0 ** 2 / msenoisyx) #B\n",
    "            psnrxxhat = 10.0 * torch.log10(1.0 ** 2 / msexhatx) #B\n",
    "            print(\"psnrnoisyx\",psnrnoisyx.size())\n",
    "            print(\"psnrxxhat\",psnrxxhat.size())\n",
    "            print(\"psnrnoisyx\",psnrnoisyx)\n",
    "            print(\"psnrxxhat\",psnrxxhat)\n",
    "            \n",
    "            \n",
    "            \n",
    "            ssimxxhattmp = ssim(x,x_hat, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimxxhat = ssimxxhattmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            \n",
    "            rssimnx += ssimnoisyx.sum(0)\n",
    "            rssimxh += ssimxxhat.sum(0)\n",
    "            \n",
    "            rpsnrxh += psnrxxhat.sum(0)\n",
    "            rpsnrnx += psnrnoisyx.sum(0)\n",
    "            #visualise\n",
    "            \n",
    "            plt.imshow(np.transpose(x[2].to(\"cpu\"), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            plt.imshow(np.transpose(noisy_x[2].to(\"cpu\"), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            plt.imshow(np.transpose(x_hat[2].to(\"cpu\"), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            print(\"ssim of this image\", ssimnoisyx[2].item(), ssimxxhat[2].item())\n",
    "            print(\"psnr of this image\", psnrnoisyx[2].item(), psnrxxhat[2].item())\n",
    "                 \n",
    "    n = 1893\n",
    "    meanssimnx = rssimnx/n\n",
    "    meanssimxh = rssimxh/n\n",
    "    \n",
    "    meanpsnrnx = rpsnrnx/n\n",
    "    meanpsnrxh = rpsnrxh/n\n",
    "    return meanssimnx, meanssimxh, meanpsnrnx, meanpsnrxh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac02abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the psnr ssim table\n",
    "def save_psnr_ssim_table(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 30,\n",
    "     'random_seed': 1996,\n",
    "     'image_size': (224,224),\n",
    "     'n_classes': 1\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}epoch_180\"\n",
    "\n",
    "    dic = {\"noise_level\":[], \"mean_ssim_noisy_x\":[], \"mean_ssim_xhat_x\":[] ,\"mean_psnr_noisy_x\":[], \"mean_psnr_xhat_x\":[]}\n",
    "    b_list = np.arange(round(1.0-model_b,1), round(1.0+model_b+0.2,1), 0.2)\n",
    "    print(\"=======================================\")\n",
    "    print(\"model_file\", model_file, \"model_b\", model_b, \"Noise_Level_Range\", b_list)\n",
    "    for b in b_list:\n",
    "        params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\": round(b,1) # is noise level\n",
    "            }\n",
    "        params = {**shared_params, **params} \n",
    "        print(\"noise_level\", round(b,1), params[\"brightness\"])\n",
    "        meanssimnx, meanssimxh, meanpsnrnx, meanpsnrxh = get_ssim_psnr_noisy_model(model_file, round(b,1), params)\n",
    "        dic[\"noise_level\"].append(round(b,1)) \n",
    "        dic[\"mean_ssim_noisy_x\"].append(meanssimnx.item()) \n",
    "        dic[\"mean_ssim_xhat_x\"].append(meanssimxh.item()) \n",
    "        dic[\"mean_psnr_noisy_x\"].append(meanpsnrnx.item()) \n",
    "        dic[\"mean_psnr_xhat_x\"].append(meanpsnrxh.item())\n",
    "        with open(f'IMAGINE_RESULTS/MODEL{model_b}_SSIM_PSNR_TABLE.pickle','wb') as handle: \n",
    "            pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f78ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = 0.8\n",
    "dic = save_psnr_ssim_table(model_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05618628",
   "metadata": {},
   "source": [
    "# Visualisation of Reconstruction In Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72bbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_report_appendix(model_file, b_list, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(len(b_list)*2+1,shared_params[\"batch_size\"] ,figsize=(50,50), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    model = torch.load(model_file)\n",
    "    added_noise_labels_appendix = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"H\",\"I\",\"J\",\"K\", \"L\"]\n",
    "    model.cuda()\n",
    "    \n",
    "    for b in range(len(b_list)):\n",
    "        params = { \n",
    "            \"gamma\": 0.01,\n",
    "            \"brightness\": round(b_list[b],1) # is noise level\n",
    "            }\n",
    "        params = {**shared_params, **params}\n",
    "        experiment_modules = set_experiment(model, params)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            x, noisy_x, y = next(iter(experiment_modules[\"added_appendix_loader\"]))\n",
    "            x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "            outputs = model(noisy_x) \n",
    "            x_hat = outputs['x_hat']\n",
    "            # qualitative scores\n",
    "            ssimnoisyxtmp = ssim(x,noisy_x, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimnoisyx = ssimnoisyxtmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            ssimxxhattmp = ssim(x,x_hat, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimxxhat = ssimxxhattmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            \n",
    "            msenoisyxtmp = mse(x,noisy_x, reduction = \"none\") # BxCxHxW\n",
    "            msexhatxtmp = mse(x,x_hat, reduction = \"none\")# BxCxHxW\n",
    "            msenoisyx = msenoisyxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            msexhatx = msexhatxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            psnrnoisyx = 10.0 * torch.log10(1.0 ** 2 / msenoisyx) #B\n",
    "            psnrxxhat = 10.0 * torch.log10(1.0 ** 2 / msexhatx) #B\n",
    "            \n",
    "            \n",
    "            ssim_psnr_values[\"ssim_noisy_x\"].append(ssimnoisyx)\n",
    "            ssim_psnr_values[\"ssim_xhat_x\"].append(ssimxxhat)\n",
    "            ssim_psnr_values[\"psnr_noisy_x\"].append(psnrnoisyx)\n",
    "            ssim_psnr_values[\"psnr_xhat_x\"].append(psnrxxhat)\n",
    "            \n",
    "            for i in range(params[\"batch_size\"]):\n",
    "                #plot images\n",
    "                axs[0,i].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #GT\n",
    "                axs[b*2+1,i].imshow(np.transpose(noisy_x[i].to(\"cpu\"), (1, 2, 0))) #noisy\n",
    "                axs[b*2+2,i].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "                axs[0,i].set_xticklabels([])\n",
    "                axs[0,i].set_yticklabels([])\n",
    "                axs[b*2+1,i].set_xticklabels([])\n",
    "                axs[b*2+1,i].set_yticklabels([])\n",
    "                axs[b*2+2,i].set_xticklabels([])\n",
    "                axs[b*2+2,i].set_yticklabels([])\n",
    "                axs[0,i].set_aspect('equal')\n",
    "                axs[b*2+1,i].set_aspect('equal')\n",
    "                axs[b*2+2,i].set_aspect('equal')\n",
    "                # add ssim and psnr of each\n",
    "                axs[16,i].set_xlabel(added_noise_labels_appendix[i], fontweight = \"bold\", fontsize = 25)\n",
    "                if i == 0:\n",
    "                    axs[0,i].set_ylabel(\"GT\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=20)\n",
    "                    axs[b*2+1,i].set_ylabel(f\"{b_list[b]}\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=60)\n",
    "                    axs[b*2+2,i].set_ylabel(f\"SDAE {b_list[b]}\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=80)    \n",
    "                \n",
    "                # add ssim and psnr of each\n",
    "                axs[b*2+1,i].text(x=10,y=10,s=f'{round(ssimnoisyx[i].item(),2)}\\n{round(psnrnoisyx[i].item(),2)}',horizontalalignment='left',verticalalignment='top', fontsize=15, fontweight=\"demi\", bbox=dict(facecolor='white', alpha=0.5))                    \n",
    "                axs[b*2+2,i].text(x=10,y=10,s=f'{round(ssimxxhat[i].item(),2)}\\n{round(psnrxxhat[i].item(),2)}',horizontalalignment='left',verticalalignment='top', fontsize=15, fontweight=\"demi\", bbox=dict(facecolor=\"white\", alpha=0.5))\n",
    "               \n",
    "    fig.suptitle('De-noising Test Images With Different Levels of Added Noise', fontsize=35, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.95, bottom=0.05)\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_IMAGINE_0.8_LARGEEPOCH_NOISERANGE{b_list}.png\".replace(',', '_').replace(\"]\",\"\").replace(\"[\",\"_\").replace(\" \",\"\")\n",
    "    plt.savefig(name)     \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "def save_added_appendix(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 11,\n",
    "     'random_seed': 1996,\n",
    "     'image_size': (224,224),\n",
    "     'n_classes': 1,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3, # L2 regularization\n",
    "     'p':1\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}epoch_180\"\n",
    "\n",
    "    b_list = [0.2,0.4,0.6,0.8,1.2,1.4,1.6, 1.8]\n",
    "    \n",
    "    ssim_psnr_values = visualise_report_appendix(model_file, b_list, shared_params)\n",
    "    return ssim_psnr_values\n",
    "\n",
    "ssim_psnr_values = save_added_appendix(0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52789f",
   "metadata": {},
   "source": [
    "# Images Visualised in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aed950",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualise_report(model_file, b_list, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(len(b_list)*2+1,shared_params[\"batch_size\"] ,figsize=(20,30), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    \n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    model = torch.load(model_file)\n",
    "    added_noise_labels_appendix = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    model.cuda()\n",
    "    \n",
    "    for b in range(len(b_list)):\n",
    "        params = { \n",
    "            \"gamma\": 0.01,\n",
    "            \"brightness\": round(b_list[b],1) # is noise level\n",
    "            }\n",
    "        params = {**shared_params, **params}\n",
    "        experiment_modules = set_experiment(model, params)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            x, noisy_x, y = next(iter(experiment_modules[\"added_report_loader\"]))\n",
    "            x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "            outputs = model(noisy_x) \n",
    "            #y_hat = outputs['y_hat'].cuda()\n",
    "            x_hat = outputs['x_hat']\n",
    "            # qualitative scores\n",
    "            ssimnoisyxtmp = ssim(x,noisy_x, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimnoisyx = ssimnoisyxtmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            ssimxxhattmp = ssim(x,x_hat, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimxxhat = ssimxxhattmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            \n",
    "            msenoisyxtmp = mse(x,noisy_x, reduction = \"none\") # BxCxHxW\n",
    "            msexhatxtmp = mse(x,x_hat, reduction = \"none\")# BxCxHxW\n",
    "            msenoisyx = msenoisyxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            msexhatx = msexhatxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            psnrnoisyx = 10.0 * torch.log10(1.0 ** 2 / msenoisyx) #B\n",
    "            psnrxxhat = 10.0 * torch.log10(1.0 ** 2 / msexhatx) #B\n",
    "            \n",
    "            \n",
    "            ssim_psnr_values[\"ssim_noisy_x\"].append(ssimnoisyx)\n",
    "            ssim_psnr_values[\"ssim_xhat_x\"].append(ssimxxhat)\n",
    "            ssim_psnr_values[\"psnr_noisy_x\"].append(psnrnoisyx)\n",
    "            ssim_psnr_values[\"psnr_xhat_x\"].append(psnrxxhat)\n",
    "            \n",
    "            for i in range(params[\"batch_size\"]):\n",
    "                \n",
    "                # add ssim and psnr of each\n",
    "                #plot images\n",
    "                axs[0,i].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #GT\n",
    "                axs[b*2+1,i].imshow(np.transpose(noisy_x[i].to(\"cpu\"), (1, 2, 0))) #noisy\n",
    "                axs[b*2+2,i].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "                axs[0,i].set_xticklabels([])\n",
    "                axs[0,i].set_yticklabels([])\n",
    "                axs[b*2+1,i].set_xticklabels([])\n",
    "                axs[b*2+1,i].set_yticklabels([])\n",
    "                axs[b*2+2,i].set_xticklabels([])\n",
    "                axs[b*2+2,i].set_yticklabels([])\n",
    "                axs[0,i].set_aspect('equal')\n",
    "                axs[b*2+1,i].set_aspect('equal')\n",
    "                axs[b*2+2,i].set_aspect('equal')\n",
    "                # add ssim and psnr of each\n",
    "                axs[8,i].set_xlabel(added_noise_labels_appendix[i], fontweight = \"bold\", fontsize = 15)\n",
    "                if i == 0:\n",
    "                    axs[0,i].set_ylabel(\"GT\", fontweight = \"bold\", fontsize = 15, rotation = 0, labelpad=20)\n",
    "                    axs[b*2+1,i].set_ylabel(f\"{b_list[b]}\", fontweight = \"bold\", fontsize = 15, rotation = 0, labelpad=30)\n",
    "                    axs[b*2+2,i].set_ylabel(f\"SDAE {b_list[b]}\", fontweight = \"bold\", fontsize = 15, rotation = 0, labelpad=40)    \n",
    "                \n",
    "                # add ssim and psnr of each\n",
    "\n",
    "                axs[b*2+1,i].text(x=10,y=10,s=f'{round(ssimnoisyx[i].item(),2)}\\n{round(psnrnoisyx[i].item(),2)}',horizontalalignment='left',verticalalignment='top', fontsize=15, fontweight=\"demi\", bbox=dict(facecolor='white', alpha=0.5))                    \n",
    "                axs[b*2+2,i].text(x=10,y=10,s=f'{round(ssimxxhat[i].item(),2)}\\n{round(psnrxxhat[i].item(),2)}',horizontalalignment='left',verticalalignment='top', fontsize=15, fontweight=\"demi\", bbox=dict(facecolor=\"white\", alpha=0.5)) \n",
    "          \n",
    "\n",
    "    fig.suptitle('De-noising Clinical Images With Different Levels of Added Noise', fontsize=25, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01, top=0.95, bottom=0.05)\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_IMAGINE_0.8_LARGEEPOCH_NOISERANGE{b_list}.png\".replace(',', '_').replace(\"]\",\"\").replace(\"[\",\"_\").replace(\" \",\"\")\n",
    "    plt.savefig(name)     \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "def save_added_report(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 4,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 1,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3, # L2 regularization\n",
    "     'p':1\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS{model_b}epoch_180\"\n",
    "\n",
    "    b_list = [0.2,0.6,1.4, 1.8]\n",
    "    ssim_psnr_values = visualise_report(model_file, b_list, shared_params)\n",
    "    return ssim_psnr_values\n",
    "\n",
    "ssim_psnr_values = save_added_report(0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb097f7d",
   "metadata": {},
   "source": [
    "# model in different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a39598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_images_epochs(epoch_list, b, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(shared_params[\"batch_size\"], len(epoch_list)+2 ,figsize=(40,40), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    \n",
    "    for m in range(len(epoch_list)):\n",
    "        model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_{epoch_list[m]}\"\n",
    "        model = torch.load(model_file)\n",
    "        model.cuda()\n",
    "        params = { \n",
    "            \"gamma\": 0.01,\n",
    "            \"brightness\": round(b,1) # is noise level\n",
    "            }\n",
    "        params = {**shared_params, **params}\n",
    "        experiment_modules = set_experiment(model, params)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            x, noisy_x, y = next(iter(experiment_modules[\"added_report_loader\"]))\n",
    "            x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "            outputs = model(noisy_x) \n",
    "            x_hat = outputs['x_hat']\n",
    "            # qualitative scores\n",
    "            ssimnoisyxtmp = ssim(x,noisy_x, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimnoisyx = ssimnoisyxtmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            ssimxxhattmp = ssim(x,x_hat, 5) #same dimension as x and noisy_x BxCxHxW\n",
    "            ssimxxhat = ssimxxhattmp.mean(-1).mean(-1).mean(-1) # size = B\n",
    "            \n",
    "            msenoisyxtmp = mse(x,noisy_x, reduction = \"none\") # BxCxHxW\n",
    "            msexhatxtmp = mse(x,x_hat, reduction = \"none\")# BxCxHxW\n",
    "            msenoisyx = msenoisyxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            msexhatx = msexhatxtmp.mean(-1).mean(-1).mean(-1) #B\n",
    "            psnrnoisyx = 10.0 * torch.log10(1.0 ** 2 / msenoisyx) #B\n",
    "            psnrxxhat = 10.0 * torch.log10(1.0 ** 2 / msexhatx) #B\n",
    "            \n",
    "            \n",
    "            ssim_psnr_values[\"ssim_noisy_x\"].append(ssimnoisyx)\n",
    "            ssim_psnr_values[\"ssim_xhat_x\"].append(ssimxxhat)\n",
    "            ssim_psnr_values[\"psnr_noisy_x\"].append(psnrnoisyx)\n",
    "            ssim_psnr_values[\"psnr_xhat_x\"].append(psnrxxhat)\n",
    "            \n",
    "            for i in range(params[\"batch_size\"]):\n",
    "                #plot images\n",
    "                axs[i,0].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #GT\n",
    "                axs[i,1].imshow(np.transpose(noisy_x[i].to(\"cpu\"), (1, 2, 0))) #noisy\n",
    "                axs[i,m+2].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "                axs[i,0].set_xticklabels([])\n",
    "                axs[i,0].set_yticklabels([])\n",
    "                axs[i,1].set_xticklabels([])\n",
    "                axs[i,1].set_yticklabels([])\n",
    "                axs[i,m+2].set_xticklabels([])\n",
    "                axs[i,m+2].set_yticklabels([])\n",
    "                axs[i,0].set_aspect('equal')\n",
    "                axs[i,1].set_aspect('equal')\n",
    "                axs[i,m+2].set_aspect('equal')\n",
    "                if i == params[\"batch_size\"]-1:\n",
    "                    axs[i,0].set_xlabel(\"GT\", fontweight = \"bold\", fontsize = 15, rotation=45)\n",
    "                    axs[i,1].set_xlabel(f\"Noisy(0.6)\", fontweight = \"bold\", fontsize = 15, rotation = 45)\n",
    "                    axs[i,m+2].set_xlabel(f\"De-noised in Epoch({epoch_list[m]})\", fontweight = \"bold\", fontsize = 15, rotation = 45)\n",
    "                \n",
    "                # add ssim and psnr of each\n",
    "                axs[i,m+2].text(x=right,y=bottom,s=f'{round(ssimxxhat[i].item(),2)}\\n{round(psnrxxhat[i].item(),2)}',horizontalalignment='left',verticalalignment='top', bbox=dict(facecolor='white', alpha=0.75))\n",
    "                axs[i,1].text(x=right,y=bottom,s=f'{round(ssimxxhat[i].item(),2)}\\n{round(psnrxxhat[i].item(),2)}',horizontalalignment='left',verticalalignment='top', bbox=dict(facecolor='white', alpha=0.75))\n",
    "    \n",
    "    fig.suptitle(f'Denoising of Some Samples in Different Epochs', fontsize=20, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.95, bottom=0.05)\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_IMAGINE_0.8_LARGEEPOCH_b{b}{epoch_list}.png\".replace(',', '_').replace(\"]\",\"\").replace(\"[\",\"_\").replace(\" \",\"\")\n",
    "    plt.savefig(name)     \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "def save_images_epochs(b, epoch_list):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 8,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 1,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3, # L2 regularization\n",
    "     'p':1\n",
    "    }\n",
    "\n",
    "    print(\"=======================================\")\n",
    "    print(\"Noise_Level\", b, \"epoch range\", epoch_list)\n",
    "    ssim_psnr_values = visualise_images_epochs(epoch_list, b, shared_params)\n",
    "    return ssim_psnr_values\n",
    "\n",
    "b = 0.6\n",
    "epoch_list = [10,100,180]\n",
    "ssim_values = save_images_epochs(b, epoch_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-suite",
   "metadata": {},
   "source": [
    "# Visualisation on The Natural Light Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17027e55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualise_images_natural(model_file, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(shared_params[\"batch_size\"],2 ,figsize=(25,10), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    model = torch.load(model_file)\n",
    "    model.cuda()\n",
    "    params = { \n",
    "        \"gamma\": 0.01,\n",
    "        \"brightness\": 0 # is noise level\n",
    "        }\n",
    "    params = {**shared_params, **params}\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        x, noisy_x, y = next(iter(experiment_modules[\"natural_loader\"]))\n",
    "        x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "        outputs = model(x) \n",
    "        x_hat = outputs['x_hat']\n",
    "        natural_labels = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "        #plot images\n",
    "        for i in range(params[\"batch_size\"]):\n",
    "            axs[i,0].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #original image\n",
    "            axs[i,1].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "            axs[i,0].set_xticklabels([])\n",
    "            axs[i,0].set_yticklabels([])\n",
    "            axs[i,1].set_xticklabels([])\n",
    "            axs[i,1].set_yticklabels([])\n",
    "            axs[i,0].set_aspect('equal')\n",
    "            axs[i,1].set_aspect('equal')\n",
    "            \n",
    "            axs[i,0].set_ylabel(natural_labels[i], fontweight = \"bold\", fontsize = 25, rotation = 0)\n",
    "            if i == params[\"batch_size\"]-1:\n",
    "                axs[i,0].set_xlabel(\"Original Image\", fontweight = \"bold\", fontsize = 25)\n",
    "                axs[i,1].set_xlabel(\"Denoised Image\", fontweight = \"bold\", fontsize = 25)\n",
    "\n",
    "    fig.suptitle(f'De-noising Naturally bad light Images', fontsize=30, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_imagine_0.8_Natural.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "\n",
    "# save the psnr ssim table\n",
    "def save_images_natural(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 10,\n",
    "     'random_seed': 1996,\n",
    "     'image_size': (224,224),\n",
    "     'n_classes': 1,\n",
    "     'p':0\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "\n",
    "    print(\"=======================================\")\n",
    "    print(\"model_file\", model_file, \"model_b\", model_b)\n",
    "    ssim_psnr_values = visualise_images_natural(model_file, shared_params)\n",
    "    return ssim_psnr_values\n",
    "ssim_psnr_values = save_images_natural(0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cce09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualise_images_dark(model_file, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(2, shared_params[\"batch_size\"] ,figsize=(25,10), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    model = torch.load(model_file)\n",
    "    model.cuda()\n",
    "    params = { \n",
    "        \"gamma\": 0.01,\n",
    "        \"brightness\": 0 # is noise level\n",
    "        }\n",
    "    params = {**shared_params, **params}\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    natural_labels = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        x, noisy_x, y = next(iter(experiment_modules[\"dark_loader\"]))\n",
    "        x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "        outputs = model(x) \n",
    "        x_hat = outputs['x_hat']\n",
    "    \n",
    "        #plot images\n",
    "        for i in range(params[\"batch_size\"]):\n",
    "            axs[0,i].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #original image\n",
    "            #axs[i,b*2+1].imshow(np.transpose(noisy_x[i].to(\"cpu\"), (1, 2, 0))) #noisy\n",
    "            axs[1,i].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "            axs[0,i].set_xticklabels([])\n",
    "            axs[0,i].set_yticklabels([])\n",
    "            axs[1,i].set_xticklabels([])\n",
    "            axs[1,i].set_yticklabels([])\n",
    "            axs[0,i].set_aspect('equal')\n",
    "            axs[1,i].set_aspect('equal')\n",
    "            \n",
    "            axs[1,i].set_xlabel(natural_labels[i], fontweight = \"bold\", fontsize = 25)\n",
    "            if i == 0:\n",
    "                axs[0,i].set_ylabel(\"Original\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=80)\n",
    "                axs[1,i].set_ylabel(\"SDAE\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=60)\n",
    "\n",
    "    fig.suptitle(f'De-noising Naturally Dark Images', fontsize=30, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout() # made adjust not work\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_imagine_0.8_DARK.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "\n",
    "# save the psnr ssim table\n",
    "def save_images_dark(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 5,\n",
    "     'random_seed': 1996,\n",
    "     'image_size': (224,224),\n",
    "     'n_classes': 1,\n",
    "     'p':0\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "    print(\"=======================================\")\n",
    "    print(\"model_file\", model_file, \"model_b\", model_b)\n",
    "    ssim_psnr_values = visualise_images_dark(model_file, shared_params)\n",
    "\n",
    "    #with open(f'exp1_benchmark/MODEL{model_b}_SSIM_PSNR_TABLE.pickle','wb') as handle: \n",
    "    #    pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return ssim_psnr_values\n",
    "ssim_psnr_values = save_images_dark(0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e535ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualise_images_light(model_file, shared_params):\n",
    "    ssim_psnr_values = {\"ssim_noisy_x\":[],\"ssim_xhat_x\":[],\"psnr_noisy_x\":[],\"psnr_xhat_x\":[]} # b_list x B x 1 each\n",
    "    fig, axs = plt.subplots(2, shared_params[\"batch_size\"] ,figsize=(25,10), subplot_kw={'xticks': [], 'yticks': []}) #hight same as batch_size, width = GT + len(b_list) *2\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    model = torch.load(model_file)\n",
    "    model.cuda()\n",
    "    params = { \n",
    "        \"gamma\": 0.01,\n",
    "        \"brightness\": 0 # is noise level\n",
    "        }\n",
    "    params = {**shared_params, **params}\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    natural_labels = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        x, noisy_x, y = next(iter(experiment_modules[\"light_loader\"]))\n",
    "        x, noisy_x, y = x.cuda(), noisy_x.cuda(), y.cuda()\n",
    "        outputs = model(x) \n",
    "        x_hat = outputs['x_hat']\n",
    "        #plot images\n",
    "        for i in range(params[\"batch_size\"]):\n",
    "            axs[0,i].imshow(np.transpose(x[i].to(\"cpu\"), (1, 2, 0))) #original image\n",
    "            #axs[i,b*2+1].imshow(np.transpose(noisy_x[i].to(\"cpu\"), (1, 2, 0))) #noisy\n",
    "            axs[1,i].imshow(np.transpose(x_hat[i].to(\"cpu\"), (1, 2, 0)))\n",
    "            axs[0,i].set_xticklabels([])\n",
    "            axs[0,i].set_yticklabels([])\n",
    "            axs[1,i].set_xticklabels([])\n",
    "            axs[1,i].set_yticklabels([])\n",
    "            axs[0,i].set_aspect('equal')\n",
    "            axs[1,i].set_aspect('equal')\n",
    "            \n",
    "            axs[1,i].set_xlabel(natural_labels[i], fontweight = \"bold\", fontsize = 25)\n",
    "            if i == 0:\n",
    "                axs[0,i].set_ylabel(\"Original\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=80)\n",
    "                axs[1,i].set_ylabel(\"SDAE\", fontweight = \"bold\", fontsize = 25, rotation = 0, labelpad=60)\n",
    "\n",
    "    fig.suptitle(f'De-noising Naturally Light Images', fontsize=30, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout() # made adjust not work\n",
    "    name = f\"IMAGINE_RESULTS/VISUALISE_imagine_0.8_LIGHT.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return ssim_psnr_values\n",
    "\n",
    "\n",
    "# save the psnr ssim table\n",
    "def save_images_light(model_b):\n",
    "    \n",
    "    shared_params = {\n",
    "     'batch_size': 5,\n",
    "     'random_seed': 1996,\n",
    "     'image_size': (224,224),\n",
    "     'n_classes': 1,\n",
    "     'p':0\n",
    "    }\n",
    "    \n",
    "    model_file = f\"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "    print(\"=======================================\")\n",
    "    print(\"model_file\", model_file, \"model_b\", model_b)\n",
    "    ssim_psnr_values = visualise_images_light(model_file, shared_params)\n",
    "    return ssim_psnr_values\n",
    "ssim_psnr_values = save_images_light(0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9218e73",
   "metadata": {},
   "source": [
    "# Loading the tables to use in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(ssim_psnr_table_path):\n",
    "    with open(ssim_psnr_table_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    df = pd.DataFrame.from_dict(x)\n",
    "    #ssim with 3 decimal\n",
    "    df[\"mean_ssim_noisy_x\"] = df[\"mean_ssim_noisy_x\"].round(2)\n",
    "    df[\"mean_ssim_xhat_x\"] = df[\"mean_ssim_xhat_x\"].round(2)\n",
    "    # psnr with 2 decimal\n",
    "    df[\"mean_psnr_noisy_x\"] = df[\"mean_psnr_noisy_x\"].round(2)\n",
    "    df[\"mean_psnr_xhat_x\"] = df[\"mean_psnr_xhat_x\"].round(2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_psnr_table_path = \"IMAGINE_RESULTS/MODEL0.8_SSIM_PSNR_TABLE.pickle\" # is with large epoch numbers\n",
    "df = get_table(ssim_psnr_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb465c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2bdbad",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch-12a48cd1e573\n",
    "def layer_visualise(model, experiment_modules):\n",
    "    x, noisy_x, y = next(iter(experiment_modules[\"added_report_loader\"]))\n",
    "    outputs = []\n",
    "    names = [\"image\", \"conv1\", \"conv2\", \"conv3\", \"conv4\", \"deconv4\", \"deconv3\", \"deconv2\", \"deconv1\"]\n",
    "\n",
    "    outputs.append(x[3])\n",
    "    image1 = model.conv1(noisy_x)\n",
    "    image1 = model.act_fn(image1)\n",
    "    outputs.append(image1[3])\n",
    "    image2 = model.conv2(image1)\n",
    "    image2 = model.act_fn(image2)\n",
    "    outputs.append(image2[3])\n",
    "    image3 = model.conv3(image2)\n",
    "    image3 = model.act_fn(image3)\n",
    "    outputs.append(image3[3])\n",
    "    image4 = model.conv4(image3)\n",
    "    image4 = model.act_fn(image4)\n",
    "    outputs.append(image4[3])\n",
    "\n",
    "    image5 = model.deconv4(image4)\n",
    "    image5 = model.act_fn(image5)\n",
    "    outputs.append(image5[3])\n",
    "\n",
    "    image6 = model.deconv3(torch.cat((image5,image3),1))\n",
    "    image6 = model.act_fn(image6)\n",
    "    outputs.append(image6[3])\n",
    "\n",
    "    image7 = model.deconv2(torch.cat((image6,image2),1))\n",
    "    image7 = model.act_fn(image7)\n",
    "    outputs.append(image7[3])\n",
    "\n",
    "    image8 = model.deconv1(torch.cat((image7,image1),1))\n",
    "    image8 = model.out_fn(image8)\n",
    "    outputs.append(image8[3])\n",
    "    #from 3d to 2D\n",
    "    processed = []\n",
    "    for feature_map in outputs:\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        gray_scale = torch.sum(feature_map,0)\n",
    "        gray_scale = gray_scale / feature_map.shape[0]\n",
    "        processed.append(gray_scale.data.cpu().numpy())\n",
    "\n",
    "    fig, axs = plt.subplots(2,5,figsize=(30,15))\n",
    "    fig.delaxes(axs[1,4])\n",
    "\n",
    "    for i in range(5):\n",
    "        im = axs[0,i].imshow(processed[i], cmap='gray')\n",
    "        divider = make_axes_locatable(axs[0,i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "        axs[0,i].axis(\"off\")\n",
    "        axs[0,i].set_title(names[i].split('(')[0], fontsize=25)\n",
    "    for i in range(4):\n",
    "        im = axs[1,i].imshow(processed[i+5], cmap='gray')\n",
    "        divider = make_axes_locatable(axs[1,i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "        axs[1,i].axis(\"off\")\n",
    "        axs[1,i].set_title(names[i+5].split('(')[0], fontsize=25)\n",
    "    fig.suptitle('Feature Maps of a Sample', fontsize=35, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.95, bottom=0.05)\n",
    "    name = f\"IMAGINE_RESULTS/MODEL_IMAGINE_far.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_visualise(model_file):\n",
    "\n",
    "    shared_params = {\n",
    "     'num_epochs': 180,\n",
    "     'batch_size': 5,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'learning_rate': 0.0001, \n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 4,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3 # L2 regularization\n",
    "    }\n",
    "    params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\": 0.4 # from 0.8 til 1.2\n",
    "        }\n",
    "    params = {**shared_params, **params} \n",
    "    model = torch.load(model_file)\n",
    "    model.to(\"cpu\")\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    layer_visualise(model, experiment_modules)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file1 = \"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "get_layer_visualise(model_file1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5da24",
   "metadata": {},
   "source": [
    "# visualising the first and last feature maps In RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch-12a48cd1e573\n",
    "def layer_visualise(model, experiment_modules):\n",
    "    x, noisy_x, y = next(iter(experiment_modules[\"train_loader\"]))\n",
    "    outputs = []\n",
    "    outputs.append(x)\n",
    "    outputs.append(noisy_x)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        result = model(noisy_x)\n",
    "        x_hat = result[\"x_hat\"]\n",
    "        outputs.append(x_hat)\n",
    "        \n",
    "    fig, axs = plt.subplots(3,3,figsize=(30,15))\n",
    "    names = [\"GT\", \"Noisy\", \"CNN-SDAE\"]\n",
    "    for i in range(3):\n",
    "        feature_map = outputs[i]\n",
    "        print(feature_map.size())\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        im1 = axs[0,i].imshow(feature_map[0, :, :].data.cpu().numpy(), cmap='Reds')\n",
    "        im2 = axs[1,i].imshow(feature_map[1, :, :].data.cpu().numpy(), cmap='Greens')\n",
    "        im3 = axs[2,i].imshow(feature_map[2, :, :].data.cpu().numpy(), cmap='Blues')\n",
    "\n",
    "        divider = make_axes_locatable(axs[0,i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im1, cax=cax, orientation='vertical')\n",
    "        axs[0,i].axis(\"off\")\n",
    "        axs[0,i].set_title(names[i], fontsize=25)\n",
    "        \n",
    "        divider = make_axes_locatable(axs[1,i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im2, cax=cax, orientation='vertical')\n",
    "        axs[1,i].axis(\"off\")\n",
    "        \n",
    "        divider = make_axes_locatable(axs[2,i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im3, cax=cax, orientation='vertical')\n",
    "        axs[2,i].axis(\"off\")\n",
    "    fig.suptitle('The Ground Truth, Noisy, and Reconstruction of a Sample in RGB', fontsize=35, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    name = f\"IMAGINE_RESULTS/MODEL_RGB_IMAGINE_0.2.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def get_layer_visualise(model_file):\n",
    "\n",
    "    shared_params = {\n",
    "     'num_epochs': 180,\n",
    "     'batch_size': 1,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'learning_rate': 0.0001, \n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 4,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3 # L2 regularization\n",
    "    }\n",
    "    params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\":0.2 # from 0.8 til 1.2\n",
    "        }\n",
    "    params = {**shared_params, **params} \n",
    "    model = torch.load(model_file)\n",
    "    model.to(\"cpu\")\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    layer_visualise(model, experiment_modules)\n",
    "    return\n",
    "model_file1 = \"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "get_layer_visualise(model_file1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aca47a",
   "metadata": {},
   "source": [
    "# Visualising filters of the first convolution in each color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c93cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_single_channel(t):\n",
    "    #https://github.com/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/6_VisualizationCNN_Pytorch/CNNVisualisation.ipynb\n",
    "    nplots = t.shape[0]*t.shape[1]\n",
    "    ncols = 12\n",
    "    \n",
    "    nrows = 1 + nplots//ncols\n",
    "    #convert tensor to numpy image\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(20,30))\n",
    "    print(t.shape[0],t.shape[1])\n",
    "    #looping through all the kernels in each channel\n",
    "    for i in range(t.shape[0]):\n",
    "        for j in range(t.shape[1]):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            if j == 0:\n",
    "                ax1.imshow(npimg, cmap='Reds')\n",
    "            if j == 1:\n",
    "                ax1.imshow(npimg, cmap='Greens')\n",
    "            if j == 2:\n",
    "                ax1.imshow(npimg, cmap='Blues')\n",
    "            \n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "    fig.suptitle('Filters of The Last Deconvolution', fontsize=35, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top = 0.95, bottom = 0.05)\n",
    "    name = f\"IMAGINE_RESULTS/dec_kernel_imagine.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def get_filters(t):\n",
    "    shared_params = {\n",
    "     'num_epochs': 180,\n",
    "     'batch_size': 1,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'learning_rate': 0.0001, \n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 4,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3 # L2 regularization\n",
    "    }\n",
    "    params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\": 0.2 # from 0.8 til 1.2\n",
    "        }\n",
    "    params = {**shared_params, **params} \n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    plot_filters_single_channel(t)\n",
    "    return\n",
    "model_file = \"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "model = torch.load(model_file)\n",
    "model.to(\"cpu\")\n",
    "weight_tensor = model.deconv1.weight.data \n",
    "get_filters(weight_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060f3fa",
   "metadata": {},
   "source": [
    "# issue with too bright added noise on the bear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71136de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch-12a48cd1e573\n",
    "\n",
    "def gray_visualise(model, experiment_modules):\n",
    "    x, noisy_x, y = next(iter(experiment_modules[\"added_report_loader\"]))\n",
    "    outputs0 = [x[0], noisy_x[0]]\n",
    "    #from 3d to 2D\n",
    "    processed = []\n",
    "    for feature_map in outputs0:\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        gray_scale = torch.sum(feature_map,0)\n",
    "        gray_scale = gray_scale / feature_map.shape[0]\n",
    "        processed.append(gray_scale.data.cpu().numpy())\n",
    "        \n",
    "    outputs1 = [x[4], noisy_x[4]]\n",
    "    #from 3d to 2D\n",
    "    for feature_map in outputs1:\n",
    "        feature_map = feature_map.squeeze(0)    \n",
    "        gray_scale = torch.sum(feature_map,0)\n",
    "        gray_scale = gray_scale / feature_map.shape[0] \n",
    "        processed.append(gray_scale.data.cpu().numpy())\n",
    "    fig, axs = plt.subplots(2,2,figsize=(30,30))\n",
    "\n",
    "    for i in range(2):\n",
    "    \n",
    "        im = axs[i,0].imshow(processed[i], cmap='gray')\n",
    "        divider = make_axes_locatable(axs[i,0])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "        axs[i,0].axis(\"off\")\n",
    "        \n",
    "        im2 = axs[i,1].imshow(processed[i+2], cmap='gray')\n",
    "        divider = make_axes_locatable(axs[i,1])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im2, cax=cax, orientation='vertical')\n",
    "        axs[i,1].axis(\"off\")       \n",
    "    axs[0,1].set_ylabel(\"GT\", fontweight = \"bold\", fontsize = 50, rotation = 0, labelpad=30)\n",
    "    axs[1,0].set_ylabel(\"Noisy (1.8)\", fontweight = \"bold\", fontsize = 30, rotation = 0, labelpad=30)    \n",
    "fig.suptitle('Ground Truth and The Noise Ige (Gray Scale)', fontsize=50, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.95, bottom=0.05)\n",
    "    name = f\"IMAGINE_RESULTS/grayscale_gt_noisy.jpeg\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def get_gray_visualise(model_file):\n",
    "\n",
    "    shared_params = {\n",
    "     'num_epochs': 180,\n",
    "     'batch_size': 7,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'learning_rate': 0.0001,\n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 4,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3 # L2 regularization\n",
    "    }\n",
    "    params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\": 1.8 # from 0.8 til 1.2\n",
    "        }\n",
    "    params = {**shared_params, **params} \n",
    "    model = torch.load(model_file)\n",
    "    model.to(\"cpu\")\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    gray_visualise(model, experiment_modules)\n",
    "    return\n",
    "\n",
    "model_file1 = \"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "get_gray_visualise(model_file1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f04082",
   "metadata": {},
   "source": [
    "# Histograms of one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_visualise(model, experiment_modules):\n",
    "    x, noisy_x, y = next(iter(experiment_modules[\"added_report_loader\"]))\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        result = model(x)\n",
    "        x_hat = result[\"x_hat\"] \n",
    "        outputs = []\n",
    "\n",
    "        outputs.append(x)\n",
    "        outputs.append(noisy_x)\n",
    "        outputs.append(x_hat)\n",
    "    \n",
    "\n",
    "    #from 3d to 2D\n",
    "    processed = []\n",
    "    for feature_map in outputs:\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        gray_scale = torch.sum(feature_map,0)\n",
    "        gray_scale = gray_scale / feature_map.shape[0]\n",
    "        processed.append(gray_scale.data.cpu().numpy())\n",
    "            \n",
    "    fig, axs = plt.subplots(2, 3 ,figsize=(30,30))\n",
    "    colors =[\"red\", \"green\", \"blue\"]\n",
    "    channels = [\"Red_channel\", \"Green_channel\", \"Blue_channel\"]\n",
    "    image = [\"GT\", \"Noisy X (1.8)\", \"SDAE\"]\n",
    "    for i in range(len(outputs)):\n",
    "        feature_map = outputs[i]\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        axs[0,i].hist(feature_map[0,:, :].reshape((-1,)).data.cpu().numpy(), bins = 'auto', color = colors[0], range=[0, 1])\n",
    "        axs[0,i].hist(feature_map[1,:, :].reshape((-1,)).data.cpu().numpy(), bins = 'auto', color = colors[1], range=[0, 1])\n",
    "        axs[0,i].hist(feature_map[2,:, :].reshape((-1,)).data.cpu().numpy(), bins = 'auto', color = colors[2], range=[0, 1])\n",
    "        axs[0,i].set_xlabel(\"Intensity\", fontweight = \"bold\", fontsize = 25)\n",
    "        axs[0,0].set_ylabel(\"Number of Pixels\", fontweight = \"bold\", fontsize = 25)\n",
    "        axs[1,0].imshow(np.transpose(x[0].to(\"cpu\"), (1, 2, 0)))\n",
    "        axs[1,1].imshow(np.transpose(noisy_x[0].to(\"cpu\"), (1, 2, 0)))\n",
    "        axs[1,2].imshow(np.transpose(x_hat[0].detach().to(\"cpu\"), (1, 2, 0)))\n",
    "        axs[1,i].set_xlabel(image[i], fontweight = \"bold\", fontsize = 25)\n",
    "        axs[1,i].set_yticklabels([])\n",
    "        axs[1,i].set_xticklabels([])\n",
    "    fig.suptitle(f'Histograms of One Image', fontsize=30, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.95)\n",
    "    name = f\"IMAGINE_RESULTS/imagine_hist.png\"\n",
    "    plt.savefig(name) \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def get_hist_visualise(model_file):\n",
    "\n",
    "    shared_params = {\n",
    "     'num_epochs': 180,\n",
    "     'batch_size': 1,\n",
    "     'random_seed': 1996,\n",
    "     'optimizer_name': 'adamW',\n",
    "     'learning_rate': 0.0001, \n",
    "     'image_size': (224,224),\n",
    "     'degrees': (-10, 10),\n",
    "     'translate': (0.0, 0.5),\n",
    "     'scale': (0.5, 0.95),\n",
    "     'dropout_p': 0.5,# dropout probability\n",
    "     'negative_slope': 0.2, # negative slope for LeakyRelu\n",
    "     'n_classes': 4,\n",
    "     'alpha':1, #weight of ssim\n",
    "     'weight_decay':1e-3 # L2 regularization\n",
    "    }\n",
    "    params = { \n",
    "\n",
    "            \"gamma\": 0.01,\n",
    "            \"p\": 1,\n",
    "            \"brightness\": 1.8 \n",
    "        }\n",
    "    params = {**shared_params, **params} \n",
    "    model = torch.load(model_file)\n",
    "    model.to(\"cpu\")\n",
    "    experiment_modules = set_experiment(model, params)\n",
    "    hist_visualise(model, experiment_modules)\n",
    "    return\n",
    "\n",
    "model_file1 = \"MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8/MAIN_BENCHMARK_LRSLOW_DROPLARGE_NOISE_EPOCHNUMBERLARGE_GAMMA0.05_P0.6_BRIGHTNESS0.8epoch_180\"\n",
    "get_hist_visualise(model_file1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
